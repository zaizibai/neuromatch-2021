{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "NOTEBOOK_EXTRACTING_BEH_FOR_PROJECT_EMOTION.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/drewwint/neuromatch-2021/blob/main/From-Adam-NOTEBOOK_EXTRACTING_BEH_FOR_PROJECT_EMOTION.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "444b7546"
      },
      "source": [
        ""
      ],
      "id": "444b7546",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9452d815",
        "outputId": "63869bcd-8961-478f-e805-c5c8a80595ee"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import csv\n",
        "print(\"Current Working Directory \",os.getcwd())\n",
        "\n",
        "#finding dir of data on my drive\n",
        "\n",
        "os.chdir(\"/Users/akrzystyniak/Downloads/hcp_task\")\n",
        "subfolders = [f.path for f in os.scandir(\"/Users/akrzystyniak/Downloads/hcp_task/subjects\") if f.is_dir()]\n",
        "subjects = np.loadtxt('/Users/akrzystyniak/Downloads/hcp_task/subjects_list.txt',dtype='str')\n",
        "\n",
        "\n",
        "RUNS   = ['LR','RL']\n",
        "N_RUNS = 2\n",
        "EXPERIMENTS = {\n",
        "    'MOTOR'      : {'cond':['lf','rf','lh','rh','t','cue']},\n",
        "    'WM'         : {'cond':['0bk_body','0bk_faces','0bk_places','0bk_tools','2bk_body','2bk_faces','2bk_places','2bk_tools']},\n",
        "    'EMOTION'    : {'cond':['fear','neut']},\n",
        "    'GAMBLING'   : {'cond':['loss','win']},\n",
        "    'LANGUAGE'   : {'cond':['math','story']},\n",
        "    'RELATIONAL' : {'cond':['match','relation']},\n",
        "    'SOCIAL'     : {'cond':['ment','rnd']}\n",
        "}\n",
        "\n",
        "\n",
        "def load_evs(subject, experiment, run):\n",
        "  \"\"\"Load EVs (explanatory variables) data for one task experiment.\n",
        "\n",
        "  Args:\n",
        "    subject (str): subject ID to load\n",
        "    experiment (str) : Name of experiment\n",
        "    run (int): 0 or 1\n",
        "\n",
        "  Returns\n",
        "    evs (list of lists): A list of frames associated with each condition\n",
        "\n",
        "  \"\"\"\n",
        "  frames_list = []\n",
        "  task_key = f'tfMRI_{experiment}_{RUNS[run]}'\n",
        "  for cond in EXPERIMENTS[experiment]['cond']:    \n",
        "    ev_file  = f\"/Users/akrzystyniak/Downloads/hcp_task/subjects/{subjects[subject]}/{experiment}/{task_key}/EVs/Stats.txt\"\n",
        "    \n",
        "    # putting the data in dictionary\n",
        "    \n",
        "    dictionary = {}\n",
        "    with open(ev_file, \"r\") as file:\n",
        "        for line in file:\n",
        "            key, value = line.strip().split(\":\")\n",
        "            dictionary[key] = value\n",
        "    \n",
        "  return dictionary\n",
        "\n",
        "# collecting the data in lists for EMOTION\n",
        "\n",
        "Face_Accuracy_EMOTION = []\n",
        "Shape_Accuracy_EMOTION = []\n",
        "Median_Face_RT_EMOTION = []\n",
        "Median_Shape_RT_EMOTION = []\n",
        "\n",
        "for i in range(0, len(subjects)):\n",
        "    \n",
        "        dictionary_LR = load_evs(i,'EMOTION',0)\n",
        "        dictionary_RL = load_evs(i,'EMOTION',1)\n",
        "        Face_Accuracy_EMOTION.append(float(dictionary_LR['Face Accuracy']))\n",
        "        Face_Accuracy_EMOTION.append(float(dictionary_RL['Face Accuracy']))\n",
        "        Shape_Accuracy_EMOTION.append(float(dictionary_LR['Shape Accuracy']))\n",
        "        Shape_Accuracy_EMOTION.append(float(dictionary_RL['Shape Accuracy']))\n",
        "        Median_Face_RT_EMOTION.append(float(dictionary_LR['Median Face RT']))\n",
        "        Median_Face_RT_EMOTION.append(float(dictionary_RL['Median Face RT']))\n",
        "        Median_Shape_RT_EMOTION.append(float(dictionary_LR['Median Shape RT']))\n",
        "        Median_Shape_RT_EMOTION.append(float(dictionary_RL['Median Shape RT']))\n",
        "\n",
        "\n",
        "\n",
        "Full_results_EMOTION = []\n",
        "n=0\n",
        "        \n",
        "for i in range(0, len(subjects)):\n",
        "    if i == 0:\n",
        "        Data_for_one_subject = [subjects[i], Face_Accuracy_EMOTION[i], Face_Accuracy_EMOTION[i+1], Shape_Accuracy_EMOTION[i], Shape_Accuracy_EMOTION [i+1], Median_Face_RT_EMOTION [i], Median_Face_RT_EMOTION [i+1], Median_Shape_RT_EMOTION [i], Median_Shape_RT_EMOTION [i+1] ]\n",
        "        Full_results_EMOTION.append (Data_for_one_subject)\n",
        "        n+=1\n",
        "    else:\n",
        "        Data_for_one_subject = [subjects[i], Face_Accuracy_EMOTION[i+n], Face_Accuracy_EMOTION[i+(n+1)], Shape_Accuracy_EMOTION[i+n], Shape_Accuracy_EMOTION [i+(n+1)], Median_Face_RT_EMOTION [i+n], Median_Face_RT_EMOTION [i+(n+1)], Median_Shape_RT_EMOTION [i+n], Median_Shape_RT_EMOTION [i+(n+1)] ]\n",
        "        Full_results_EMOTION.append (Data_for_one_subject)\n",
        "        n+=1\n",
        "        \n",
        "#print(Full_results_EMOTION)\n",
        "\n",
        "# saving to CSV\n",
        "\n",
        "f = open('/Users/akrzystyniak/Desktop/results.csv', 'w')\n",
        "writer = csv.writer(f, delimiter=',')\n",
        "writer.writerow(['Subject NO','Face_Accuracy_EMOTION LR', 'Face_Accuracy_EMOTION RL', 'Shape_Accuracy_EMOTION LR', 'Shape_Accuracy_EMOTION RL', 'Median_Face_RT_EMOTION LR', 'Median_Face_RT_EMOTION RL', 'Median_Shape_RT_EMOTION LR', 'Median_Shape_RT_EMOTION RL'] )\n",
        "for i in range(0,len(Full_results_EMOTION)):\n",
        "    writer.writerow(Full_results_EMOTION[i])\n",
        "f.close()\n",
        "\n",
        "            \n",
        "            \n",
        "            \n",
        "            "
      ],
      "id": "9452d815",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Current Working Directory  /Users/akrzystyniak/Downloads/hcp_task\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}